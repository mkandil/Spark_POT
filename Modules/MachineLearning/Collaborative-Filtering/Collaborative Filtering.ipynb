{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Machine Learning with Spark\n",
    "\n",
    "##### \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E\"\n",
    "-Tom M. Mitchell\n",
    "\n",
    "#### Machine Learning - the science of getting computers to act without being explicitly programmed\n",
    "\n",
    "MLlib is Sparkâ€™s machine learning (ML) library. Its goal is to make practical machine learning scalable and easy. It consists of common learning algorithms and utilities, including classification, regression, clustering, collaborative filtering (this example!), dimensionality reduction, as well as lower-level optimization primitives and higher-level pipeline APIs.\n",
    "\n",
    "It divides into two packages:\n",
    "- spark.mllib contains the original API built on top of RDDs.\n",
    "- spark.ml provides higher-level API built on top of DataFrames for constructing ML pipelines.\n",
    "\n",
    "\n",
    "Using spark.ml is recommended because with DataFrames the API is more versatile and flexible. But we will keep supporting spark.mllib along with the development of spark.ml. Users should be comfortable using spark.mllib features and expect more features coming.\n",
    "\n",
    "http://spark.apache.org/docs/latest/mllib-guide.html\n",
    "\n",
    "## Online Purchase Recommendations\n",
    "\n",
    "Learn how to create a recommendation engine using the Alternating Least Squares algorithm in Spark's machine learning library\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/ALS.png' width=\"70%\" height=\"70%\"></img>\n",
    "\n",
    "### The data\n",
    "\n",
    "This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.  The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Online+Retail\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/FullFile.png' width=\"80%\" height=\"80%\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Section 0: </span> <br>Obtaining the dataset and performing initial prep work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-07-14 19:32:55--  https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/OnlineRetail.csv.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7483128 (7.1M) [application/octet-stream]\n",
      "Saving to: 'OnlineRetail.csv.gz'\n",
      "\n",
      "100%[======================================>] 7,483,128   44.8MB/s   in 0.2s   \n",
      "\n",
      "2016-07-14 19:32:56 (44.8 MB/s) - 'OnlineRetail.csv.gz' saved [7483128/7483128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm 'OnlineRetail.csv.gz' -f\n",
    "!wget https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/OnlineRetail.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the csv into an RDD (at first, each row in the RDD is a string which corresponds to a line in the csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country', u'536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/10 8:26,2.55,17850,United Kingdom']\n"
     ]
    }
   ],
   "source": [
    "loadRetailData = sc.textFile(\"./OnlineRetail.csv.gz\")\n",
    "print loadRetailData.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and shape the data:  \"80% of a Data Scientists  job\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the header from the RDD and split the string in each row by comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'536365', u'85123A', u'WHITE HANGING HEART T-LIGHT HOLDER', u'6', u'12/1/10 8:26', u'2.55', u'17850', u'United Kingdom'], [u'536365', u'71053', u'WHITE METAL LANTERN', u'6', u'12/1/10 8:26', u'3.39', u'17850', u'United Kingdom']]\n"
     ]
    }
   ],
   "source": [
    "header = loadRetailData.first()\n",
    "loadRetailData = loadRetailData.filter(lambda line: line != header).\\\n",
    "                            map(lambda l: l.split(\",\"))\n",
    "\n",
    "print loadRetailData.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE:  The original file at UCI's Machine Learning Repository has commas in the product description.  Those have been removed to speed up the lab.\n",
    "#### Only keep rows that have a purchase quantity of greater than 0, a customerID not equal to 0, and a non blank stock code after removing non-numeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'536365', u'85123A', u'WHITE HANGING HEART T-LIGHT HOLDER', u'6', u'12/1/10 8:26', u'2.55', u'17850', u'United Kingdom'], [u'536365', u'71053', u'WHITE METAL LANTERN', u'6', u'12/1/10 8:26', u'3.39', u'17850', u'United Kingdom']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "loadRetailData = loadRetailData.filter(lambda l: int(l[3]) > 0\\\n",
    "                                and len(re.sub(\"\\D\", \"\", l[1])) != 0 \\\n",
    "                                and len(l[6]) != 0)\n",
    "\n",
    "print loadRetailData.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map each line to a row and create a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- custId: long (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- inv: long (nullable = true)\n",
      " |-- invDate: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quant: long (nullable = true)\n",
      " |-- stockCode: long (nullable = true)\n",
      "\n",
      "None\n",
      "          country  custId                         description     inv  \\\n",
      "0  United Kingdom   17850  WHITE HANGING HEART T-LIGHT HOLDER  536365   \n",
      "1  United Kingdom   17850                 WHITE METAL LANTERN  536365   \n",
      "\n",
      "        invDate  price  quant  stockCode  \n",
      "0  12/1/10 8:26   2.55      6      85123  \n",
      "1  12/1/10 8:26   3.39      6      71053  \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#Convert each line to a Row.\n",
    "loadRetailData = loadRetailData.map(lambda l: Row(inv=int(l[0]),\\\n",
    "                                    stockCode=int(re.sub(\"\\D\", \"\", l[1])),\\\n",
    "                                    description=l[2],\\\n",
    "                                    quant=int(l[3]),\\\n",
    "                                    invDate=l[4],\\\n",
    "                                    price=float(l[5]),\\\n",
    "                                    custId=int(l[6]),\\\n",
    "                                    country=l[7]))\n",
    "\n",
    "# Infer the schema, and register the DataFrame as a table.\n",
    "retailDf = sqlContext.createDataFrame(loadRetailData)\n",
    "print retailDf.printSchema()\n",
    "\n",
    "retailDf.registerTempTable(\"retailPurchases\")\n",
    "print sqlContext.sql(\"SELECT * FROM retailPurchases limit 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA EXTRACTION FOR THE RECOMMENDATION ENGINE\n",
    "#### Extract from the reatailDf dataframe the columns which are needed for the recommendation engine: custId, stockCode and the customer's preference for a product, which is not available explicitly, so it will be \"approximated\" by the number of times a customer buys a product (<span style=\"color:blue\">quantity</span>).\n",
    "#### Note as well that the recommendation engine expects an integer datatype for both the customer id and the stock code, and a double value for the customer ranking or preference. The columns are therefore casted to the proper datatype as part of the SQL statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+\n",
      "|custId|stockCode|preference|\n",
      "+------+---------+----------+\n",
      "| 12838|    22941|       1.0|\n",
      "| 17968|    22731|       1.0|\n",
      "| 16210|    20977|       1.0|\n",
      "| 17897|    84558|       1.0|\n",
      "| 16552|    85123|       1.0|\n",
      "| 17905|    21662|       1.0|\n",
      "| 13468|    21231|       2.0|\n",
      "| 16274|    21809|       2.0|\n",
      "| 13090|    22617|       9.0|\n",
      "| 16186|    22865|       4.0|\n",
      "+------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    cast(custId as integer), cast(stockCode as integer), cast(count(*) as double) as preference\n",
    "FROM \n",
    "    retailPurchases \n",
    "group \n",
    "    by custId, stockCode\"\"\"\n",
    "retailDf = sqlContext.sql(query)\n",
    "\n",
    "retailDf.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly split the data into a testing set (20% of the data), and a training set (80% of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(custId=12838, stockCode=22941, preference=1.0), Row(custId=16210, stockCode=20977, preference=1.0)]\n",
      "[Row(custId=17968, stockCode=22731, preference=1.0), Row(custId=17897, stockCode=84558, preference=1.0)]\n"
     ]
    }
   ],
   "source": [
    "testDf, trainDf = retailDf.randomSplit([.2,.8],1)\n",
    "\n",
    "print testDf.take(2)\n",
    "print trainDf.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of <span style=\"color:blue\">Section 0 </span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the rest of this tutorial, we will build different recommendation engines, following an identical approach but using a few different options / alternatives offered by the Apache Spark libraries MLlib and Spark ML. \n",
    "### Examples of the alternatives which will be explored include using the original RDD based Spark MLlib library, versus the more recent (dataframe based) Spark ML, as well as comparing results when using the option which differentiates between EXPLICIT customer feedback (usually provided by rating a product), versus the more common IMPLICIT customer feedback (usually derived from customer behavior)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Build recommendation models. We will have 4 sections:</span> \n",
    "## <span style=\"color:blue\">Section 1-</span> Use the MLlib library assuming EXPLICIT customer feedback\n",
    "## <span style=\"color:blue\">Section 2-</span> Use the MLlib library assuming IMPLICIT customer feedback\n",
    "## <span style=\"color:blue\">Section 3-</span> Use the Spark ML library assuming EXPLICIT customer feedback\n",
    "## <span style=\"color:blue\">Section 4-</span> Use the Spark ML library assuming IMPLICIT customer feedback\n",
    "\n",
    "#### Use training DF to train a model with Alternating Least Squares \n",
    "Latent Factors / rank<br>\n",
    "The number of columns in the user-feature and product-feature matricies)<br>\n",
    "Iterations / maxIter<br>\n",
    "The number of factorization runs<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Section 1 (Please ensure you've run Section 0 above)</span>\n",
    "### Use MLlib library and (assume) EXPLICIT user feedback on product ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 1.1: Training the explicit MLlib model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some imports\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "\n",
    "# Convert the trainDf dataframe (defined above) to the underlying RDD. It should be noted that \n",
    "# these conversions have a cost... We will test shortly in a subsequent paragrapah whether the \n",
    "# MLlib algorithm can ingest directly the dataframe, which would be more convenient since data \n",
    "# frames can be queried using SQL or the Domain Specific Langue which is SQL-like.\n",
    "trainRDD = trainDf.rdd\n",
    "\n",
    "# We are casting below the elements of the RDD to \"Rating\" objects, corresponding to the\n",
    "# input which is expected by the Spark ALS algorithm. The definition of this ALS \n",
    "# Rating class can be found fairly easily online and looks as follows:  \n",
    "# Rating(user: Int, product: Int, rating: Double)\n",
    "trainRDDAsRating = trainRDD.map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n",
    "\n",
    "# As it will also become apparent using the RDD below, the explicit casting of the ALS input \n",
    "# elements to Rating objects is not required, and keeping the original triplets with the \n",
    "# proper data types appears to be sufficient as well.\n",
    "trainRDDNoRating = trainRDD.map(lambda l: (int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating(user=17968, product=22731, rating=1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the first elements of the RDD made of \"Rating\" objects. As expected, the\n",
    "# Rating class is made of the three fields mentioned above: user (integer), product (integer) \n",
    "# and rating (double)\n",
    "trainRDDAsRating.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17968, 22731, 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also take a look at the first element of the RDD made from basic triplets.\n",
    "trainRDDNoRating.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been trained\n"
     ]
    }
   ],
   "source": [
    "# Prepare to train the model, using a basic choice of hyper parameters for the ALS algorithm.\n",
    "rank = 5\n",
    "numIterations = 15\n",
    "alpha = 0.01\n",
    "lambda1 = 0.01\n",
    "\n",
    "# Train the model using the Rating class\n",
    "model = ALS.train(trainRDD, rank, numIterations, 0.01, -1, False, 10)\n",
    "\n",
    "# Train the model using the basic triplets instead of the \"Rating\" class. It can be verified\n",
    "# that this works in the same way and produces the same model. We can replace \"model\" by \n",
    "# \"modelNoRating\" in the cells below which will not cause any difference in the results\n",
    "modelNoRating = ALS.train(trainRDDNoRating, rank, numIterations, 0.01, -1, False, 10)\n",
    "\n",
    "print \"The model has been trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 1.2: Building the test RDD</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that the ALS model has been trained, it needs to be tested for accuracy. Remember that the original dataset was split into a training and testing set. We will use the testing set for this purpose. The testing set has three fields: user, product, rating and we need to eliminate the third field (column) in order to produce an RDD of the format (user, product), which is done in the cell below. This RDD will be used by the prediction logic to produce a new RDD which has the prediction/recommendation column added to the original two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((12838, 22941), 1.0), ((16210, 20977), 1.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The testing set was obtained as a subset of the overall dataset, so it contains as well\n",
    "# three fields, namely: user, product, rating.\n",
    "testRDD = testDf.rdd\n",
    "\n",
    "# testRDD0 is shaped to keep the original three fields: user, product, rating where the\n",
    "# user and product are grouped into a tuple acting as the key in a (key, value) pair... The\n",
    "# value being the rating. This RDD is going to be needed, once we get predictions from the\n",
    "# model, to compare original user ratings with the ones produced by the model, in order to\n",
    "# calculate its accuracy.\n",
    "testRDD0 = testRDD.map(lambda Row: ((Row[0], Row[1]), Row[2]))\n",
    "\n",
    "# testRDD1 below corresponds to the testRDD where the original user rating is eliminated. This\n",
    "# RDD will be used as input for generating predictions\n",
    "testRDD1 = testRDD.map(lambda Row: (Row[0], Row[1]))\n",
    "\n",
    "# Verify the proper formatting of testRDD0 by taking a look at the first element(s)\n",
    "testRDD0.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 1.3: Getting predictions using the explicit MLlib model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = model.predictAll(testRDD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=17883, product=21000, rating=0.7812946517353289),\n",
       " Rating(user=13700, product=22900, rating=1.9396991247054494),\n",
       " Rating(user=15201, product=22900, rating=-1.3326617632247206),\n",
       " Rating(user=16504, product=22900, rating=1.2932833403922677),\n",
       " Rating(user=18005, product=22900, rating=0.889831456012337)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The RDD predict above now has the model generated ratings added to it. The closer those\n",
    "# ratings are to the original user ratings we had in the testRDD, the more accurate the model\n",
    "# will be.\n",
    "predict.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:green\">Section 1.4: Comparing user entries with predicted ratings and getting a Mean Squared Error</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17883, 21000), 0.7812946517353289)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next task will consist in joining this new RDD of predictions with the original testRDD\n",
    "# in order to compare original and generated ratings. We will therefore shape this new RDD\n",
    "# as a (key, value) pair RDD where the key will correspond to a tuple consisting of the same\n",
    "# two fields (user, product) as in the testRDD. This is achieved with the transformation below.\n",
    "predict = predict.map(lambda r: ((r.user, r.product), r.rating))\n",
    "predict.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16201, 20717), (1.455879040687113, 1.0))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now proceed with the joining of both RDDs, on the (user, product) field.\n",
    "ratesAndPreds = predict.join(testRDD0)\n",
    "ratesAndPreds.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.67109648124\n"
     ]
    }
   ],
   "source": [
    "# The resulting RDD, named ratesAndPreds, has therefore the pair (user, product) as its key,\n",
    "# and the original and generated ratings as the values. We can therefore calculate the average\n",
    "# of the difference between the two values as follows. (Mean Squared Error)\n",
    "MSE = ratesAndPreds.map(lambda l: (l[1][0]- l[1][1])**2).mean()\n",
    "print MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An MSE value by itself is not a meaningful number as it needs to be compared with other values in an iterative process in order to identify the best hyper parameters for the ALS algorithm in this particular scenario. This can be left as an exercise..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now perform the same steps performed above, but trying to manipulate dataframes whenever possible rather than RDDs, since joining dataframes can be more easily done using SQL syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 1.5: Training explicit MLlib model, working with dataframes</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been trained\n"
     ]
    }
   ],
   "source": [
    "# Prepare and test a model where we pass the training dataframe directly, containing the three\n",
    "# required fields for ALS: user, product, rating\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "rank = 5\n",
    "numIterations = 15\n",
    "alpha = 0.01\n",
    "lambda1 = 0.01\n",
    "\n",
    "modeldf = ALS.train(trainDf, rank, numIterations, 0.01, -1, False, 10)\n",
    "\n",
    "print \"The model has been trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(user=12838, product=22941)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As performed in previous steps above, we will now extract the (user, product) pair from the \n",
    "# testDf and drop the rating column, since it gets added by the prediction logic.\n",
    "testDf2 = testDf.map(lambda l: (l[0], l[1])).toDF([\"user\", \"product\"])\n",
    "testDf2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get now the predictions for testDf2. Note that we need to pass in the underlying RDD to\n",
    "# predictAll. Passing in the DataFrame returns an error indicating that the method expects\n",
    "# an RDD.\n",
    "# Performance enhancement: It is not necessary (except for educational purposes in a tutorial)\n",
    "# to make testDf2 a dataframe since predictAll below requires an RDD. Consequently, we can \n",
    "# probably avoid converting the result of the lambda transformation back to a dataframe...\n",
    "predictUsingDf = modeldf.predictAll(testDf2.rdd)\n",
    "\n",
    "#predictUsingDf is an RDD of \"Rating\" objects comprised of the fields: user, product, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating(user=17883, product=21000, rating=0.7812946517353289)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first element of predictUsingDf.\n",
    "predictUsingDf.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we will rebuild a data frame from the RDD predictUsingDf, so as to be able to use SQL to\n",
    "# compare the original ratings with the ones generated by the recommendation engine.\n",
    "predictDf = predictUsingDf.map(lambda r: (r.user, r.product, r.rating)).\\\n",
    "map(lambda (a,b,c): Row(a,b,c)).toDF([\"user\", \"product\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------------------+\n",
      "| user|product|             rating|\n",
      "+-----+-------+-------------------+\n",
      "|17883|  21000| 0.7812946517353289|\n",
      "|13700|  22900| 1.9396991247054494|\n",
      "|15201|  22900|-1.3326617632247206|\n",
      "|16504|  22900| 1.2932833403922677|\n",
      "|18005|  22900|  0.889831456012337|\n",
      "+-----+-------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify that the dataframe was built correctly by looking up a few elements.\n",
    "predictDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now proceed with the same approach used above, where the ratings generated by the recommendation engine and those originally available in the dataset are brought together in the same structure for comparison. The difference with the previous method is that we are going to use an SQL join instead of the RDD join, which is more convenient and also (potentially) more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+-----+-------+------------------+\n",
      "|custId|stockCode|preference| user|product|            rating|\n",
      "+------+---------+----------+-----+-------+------------------+\n",
      "| 12347|    84991|       3.0|12347|  84991|2.1611118780423353|\n",
      "| 12347|    84997|       3.0|12347|  84997| 6.430063588583876|\n",
      "| 12347|    47559|       3.0|12347|  47559|1.6197763913083667|\n",
      "| 12347|    22376|       3.0|12347|  22376|1.7577461522484379|\n",
      "| 12347|    21791|       3.0|12347|  21791|1.9615753117557606|\n",
      "| 12347|    22492|       3.0|12347|  22492|2.2913006447658004|\n",
      "| 12347|    20719|       4.0|12347|  20719| 2.659215206985238|\n",
      "| 12347|    84558|       5.0|12347|  84558|1.7344275232546358|\n",
      "| 12352|    22779|       3.0|12352|  22779|2.1602474136825043|\n",
      "| 12359|    82613|       3.0|12359|  82613|1.7254139125447852|\n",
      "+------+---------+----------+-----+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# This dataframe contains the original rating value. Register it as a table.\n",
    "testDf.registerTempTable(\"testDf\")\n",
    "\n",
    "# This dataframe contains the generated ratings. Register it as a table.\n",
    "predictDf.registerTempTable(\"predictDf\")\n",
    "\n",
    "# Join both tables.\n",
    "join = \"\"\"\n",
    "SELECT \n",
    "    custId, stockCode, preference, user, product, rating\n",
    "FROM \n",
    "    testDf, predictDf \n",
    "WHERE\n",
    "    custId = user and stockCode = product\"\"\"\n",
    "joinDf = sqlContext.sql(join)\n",
    "\n",
    "#Print a few rows from the join result\n",
    "print joinDf.filter(\"preference >=3\").orderBy(\"custId\", \"preference\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Mean Squared Error, and unsurprisingly, it is exactly the same value as previously calculated, since the same hyper parameters were used to train the model, and the usage of data frames versus RDDs does not affect the model which is produced by Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.67109648124\n"
     ]
    }
   ],
   "source": [
    "# Compute the Mean Squared Error. Note that we can refer to the columns by name instead of by\n",
    "# index...\n",
    "MSE = joinDf.map(lambda l: (l.preference - l.rating)**2).mean()\n",
    "print MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 1.6: Manual verification of ALS recommendations for one chosen customer</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now work on verifying \"manually\" the efficiency of our model. In order to do so, we will pick one customer who bought a reasonably small, yet meaningful number of items (i.e more than one or two, but not dozens) and check the top three recommendations for that particular customer in order to decide whether these make sense or not. To begin, we write a SQL query to find customers ids who bought a reasonable number of items, i.e between 5 and 10. We start with a count of 7 items (feel free to update the query below with a different count for other attemps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(custId=17639, count=7),\n",
       " Row(custId=18048, count=7),\n",
       " Row(custId=16248, count=7),\n",
       " Row(custId=15257, count=7),\n",
       " Row(custId=15463, count=7),\n",
       " Row(custId=18269, count=7),\n",
       " Row(custId=13876, count=7),\n",
       " Row(custId=12884, count=7),\n",
       " Row(custId=14494, count=7),\n",
       " Row(custId=14500, count=7)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The order by clause in the query below has been added in case the having clause is changed\n",
    "# to an inequality rather than an equality (i.e something like having count > 5 ...)\n",
    "query = \"\"\"select custId, count(*) as count from retailPurchases \n",
    "           group by custId having count = 7 order by count\"\"\"\n",
    "\n",
    "sqlContext.sql(query).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the results of the SQL query above, we arbitrarily pick one of the customers ids and inject it in the query below in order to find out what items this person bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stockCode=22809, description=u'SET OF 6 T-LIGHTS SANTA'),\n",
       " Row(stockCode=23157, description=u'SET OF 6 NATIVITY MAGNETS '),\n",
       " Row(stockCode=22865, description=u'HAND WARMER OWL DESIGN'),\n",
       " Row(stockCode=23419, description=u'HOME SWEET HOME BOTTLE '),\n",
       " Row(stockCode=22866, description=u'HAND WARMER SCOTTY DOG DESIGN'),\n",
       " Row(stockCode=23155, description=u'KNICKERBOCKERGLORY MAGNET ASSORTED '),\n",
       " Row(stockCode=23156, description=u'SET OF 5 MINI GROCERY MAGNETS')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"SELECT distinct stockCode, description from retailPurchases \n",
    "               where custId in (16248)\"\"\").take(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the top 3 recommendations for the user chosen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=16248, product=2, rating=4.293959165449962),\n",
       " Rating(user=16248, product=15056, rating=3.0547204883131953),\n",
       " Rating(user=16248, product=17012, rating=2.84352985063404)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldf.recommendProducts(16248,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the SQL query below to quickly lookup the text description of the recommendations above. It can be noticed that some items use multiple text descriptions for the same stockCode (<span style=\"color:red\">possible further data cleaning opportunity here...</span>), which is the reason why we select several rows from the resulting dataframe. \n",
    "#### <span style=\"color:green\">There is some randomness injected in the recommendations, so it might not be possible to get the exact same results for consecutive runs...</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stockCode=15056, description=u'EDWARDIAN PARASOL PINK'),\n",
       " Row(stockCode=17012, description=u'ORIGAMI LAVENDER INCENSE/CANDL SET '),\n",
       " Row(stockCode=17012, description=u'ORIGAMI JASMINE INCENSE/CANDLE SET'),\n",
       " Row(stockCode=17012, description=u'ORIGAMI VANILLA INCENSE/CANDLE SET '),\n",
       " Row(stockCode=17012, description=u'ORIGAMI OPIUM INCENSE/CANDLE SET '),\n",
       " Row(stockCode=15056, description=u'EDWARDIAN PARASOL BLACK'),\n",
       " Row(stockCode=15056, description=u'EDWARDIAN PARASOL NATURAL'),\n",
       " Row(stockCode=17012, description=u'ORIGAMI ROSE INCENSE/CANDLE SET '),\n",
       " Row(stockCode=17012, description=u'ORIGAMI SANDLEWOOD INCENSE/CAND SET')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"SELECT distinct stockCode, description from retailPurchases \n",
    "               where stockCode in (17012, 15056)\"\"\").take(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 1.7: Analyzing the ALS recommendation engine for data (customer ids) which did not exist in the training set...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra-credit activity: Remember that the original data set was randomly split between training and testing set (80% , 20%). This means that some users may be present in the testing set but not in the training set. Finding those users can be achieved in several different ways. Below is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|custId|custId|\n",
      "+------+------+\n",
      "| 15442|  null|\n",
      "| 16462|  null|\n",
      "| 12665|  null|\n",
      "| 12665|  null|\n",
      "| 15269|  null|\n",
      "| 15269|  null|\n",
      "| 17896|  null|\n",
      "| 17896|  null|\n",
      "| 15098|  null|\n",
      "| 15100|  null|\n",
      "| 14705|  null|\n",
      "| 13307|  null|\n",
      "| 15510|  null|\n",
      "| 13120|  null|\n",
      "| 13135|  null|\n",
      "| 15940|  null|\n",
      "| 16144|  null|\n",
      "| 12346|  null|\n",
      "| 16148|  null|\n",
      "| 17948|  null|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find users which were in the testing set but not in the training set\n",
    "trainDf.registerTempTable(\"trainDf\")\n",
    "testDf.registerTempTable(\"testDf\")\n",
    "query = \"\"\"\n",
    "SELECT testDf.custId, trainDf.custId FROM\n",
    "testDf LEFT OUTER JOIN trainDf\n",
    "ON testDf.custId = trainDf.custId\n",
    "where isNull(trainDf.custId)\n",
    "\"\"\"\n",
    "joinDf = sqlContext.sql(query)\n",
    "\n",
    "joinDf.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's pick one of the customer ids which was present in the testing set but not in the training set and get the top 3 recommendations. \n",
    "### The execution of the cell below should return an error due to the fact that the model never obtained data for a user which was not present in the training set. Consequently, it makes sense to cleanup the testing set by removing all users and products which were not present in the training set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "modeldf.recommendProducts(16462,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can verify this in a different way, by comparing the number of entries which were fed into the model and the number of entries it produced. Those were respectively the RDDs / dataframes <span style=\"color:red\">testDf2</span> and <span style=\"color:red\">predictUsingDf</span> higher up in Section 1.5\n",
    "### It can be noticed that some entries did not produce a recommendation and those correspond to customer ids which the trained model does not know about (also known as the <span style=\"color:red\">cold start</span> problem: what to recommend for a new customer who has never provided any ratings or preferences).\n",
    "### It can be noticed as well that the remarks made for customer ids can also be made for stock ids, and a best practice would be to ensure that the randomly generated test set is similar in distributions to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51996"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDf2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51953"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictUsingDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib also provides a recommendFeatures API, which will return the top users for a given product <span style=\"color:red\">Hand Warmer Owl Design</span>. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=16422, product=22865, rating=12.731184377356648),\n",
       " Rating(user=17841, product=22865, rating=10.958900034487785),\n",
       " Rating(user=13777, product=22865, rating=8.051914800487737)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldf.recommendUsers(22865,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an SQL query in which we can inject the customer ids to identify the products which were bought. A further analysis of the results ise left as an exercise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stockCode=22654, description=u'DELUXE SEWING KIT '),\n",
       " Row(stockCode=22942, description=u'CHRISTMAS LIGHTS 10 SANTAS '),\n",
       " Row(stockCode=23190, description=u'BUNDLE OF 3 SCHOOL EXERCISE BOOKS  '),\n",
       " Row(stockCode=21390, description=u'FILIGRIS HEART WITH BUTTERFLY'),\n",
       " Row(stockCode=22118, description=u'JOY WOODEN BLOCK LETTERS'),\n",
       " Row(stockCode=22970, description=u'LONDON BUS COFFEE MUG'),\n",
       " Row(stockCode=72780, description=u'BLACK SILOUETTE CANDLE PLATE'),\n",
       " Row(stockCode=21462, description=u'NURSERY ABC PAINTED LETTERS'),\n",
       " Row(stockCode=21269, description=u'ANTIQUE CREAM CUTLERY SHELF '),\n",
       " Row(stockCode=22695, description=u'WICKER WREATH SMALL'),\n",
       " Row(stockCode=22339, description=u'CHRISTMAS TREE PAINTED ZINC '),\n",
       " Row(stockCode=85064, description=u'CREAM SWEETHEART LETTER RACK'),\n",
       " Row(stockCode=22996, description=u'TRAVEL CARD WALLET VINTAGE TICKET'),\n",
       " Row(stockCode=84596, description=u'SMALL DOLLY MIX DESIGN ORANGE BOWL'),\n",
       " Row(stockCode=21902, description=u'KEY FOB  FRONT  DOOR '),\n",
       " Row(stockCode=84912, description=u'GREEN ROSE WASHBAG'),\n",
       " Row(stockCode=21132, description=u'SILVER STANDING GNOME   '),\n",
       " Row(stockCode=16014, description=u'SMALL CHINESE STYLE SCISSOR'),\n",
       " Row(stockCode=21942, description=u'SKULLS DESIGN FLANNEL'),\n",
       " Row(stockCode=20707, description=u'CRAZY DAISY HEART DECORATION'),\n",
       " Row(stockCode=85170, description=u'SET/6 BLACK BIRD T-LIGHT CANDLES'),\n",
       " Row(stockCode=23397, description=u'FOOT STOOL HOME SWEET HOME '),\n",
       " Row(stockCode=23348, description=u'CHILDRENS TOY COOKING UTENSIL SET'),\n",
       " Row(stockCode=23402, description=u'HOME SWEET HOME 3 PEG HANGER '),\n",
       " Row(stockCode=20992, description=u'JAZZ HEARTS PURSE NOTEBOOK'),\n",
       " Row(stockCode=23413, description=u'DECORATIVE VINTAGE COFFEE  BOX'),\n",
       " Row(stockCode=22379, description=u'RECYCLING BAG RETROSPOT '),\n",
       " Row(stockCode=22677, description=u'FRENCH BLUE METAL DOOR SIGN 2'),\n",
       " Row(stockCode=23134, description=u'LARGE ZINC HEART WALL ORGANISER'),\n",
       " Row(stockCode=22621, description=u'TRADITIONAL KNITTING NANCY'),\n",
       " Row(stockCode=22155, description=u'STAR DECORATION RUSTIC'),\n",
       " Row(stockCode=23681, description=u'LUNCH BAG RED VINTAGE DOILY'),\n",
       " Row(stockCode=22394, description=u'PAPERWEIGHT KINGS CHOICE '),\n",
       " Row(stockCode=23407, description=u'SET OF 2 TRAYS HOME SWEET HOME'),\n",
       " Row(stockCode=22843, description=u'BISCUIT TIN VINTAGE GREEN')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"SELECT distinct stockCode, description from retailPurchases \n",
    "                  where custId in (17841)\"\"\").take(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:green\">Section 1.8: A Quick look under the hood..</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib gives access to the user and product features matrices mentioned at the beginning of this lab. The ratings for each user and product are obtained as a result of the dot product of the user Vector and Product vector from these matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a row from the userFeatures matrix. We have selected the features for the user we have been working with so far: <span style=\"color:red\">16248</span>. Notice the number of Features \"5\" which corresponds to the <span style=\"color:red\">rank</span> parameters which was used to train the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array('d', [0.282953679561615, -0.9585980772972107, 0.1316331923007965, 0.20625106990337372, -0.09942080825567245])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.userFeatures().lookup(16248)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is another view, taking the first two elements of the <span style=\"color:red\">Features</span> matrix. We see the features associated with two products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20700,\n",
       "  array('d', [0.6529210805892944, -0.6889617443084717, 0.08246684074401855, 0.1900530457496643, -0.14447906613349915])),\n",
       " (21000,\n",
       "  array('d', [1.2690746784210205, -0.13172782957553864, 0.2237655222415924, 0.6966758370399475, -0.593940258026123]))]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.productFeatures().take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Additional work will be suggested at the end of this lab in manipulating these user and product features in more detail...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Section 2 (Please ensure you've run Section 0 above)</span>\n",
    "### Use MLlib library and (assume) IMPLICIT user feedback on product ratings.\n",
    "### We will continue using data frames for convenience.\n",
    "\n",
    "### In implicit feedback rating, the ALS algorithm will adapt its internal weights to treat the provided user ratings as being derived through some process rather than being directly given by the user. This is closer to reality in our example, since the number of items purchased by the user were used as a form of representing the user preference for that item.<br> <br>The general flow of the approach will however remain identical to the one in Section 1 above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 2.1: Training the implicit MLlib model.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelImplicit1 has been trained\n"
     ]
    }
   ],
   "source": [
    "# Working with Implicit Feedback (We will treat the number of times a customer bought an item\n",
    "# as implicit feedback by using trainImplicit)\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "rank = 5\n",
    "numIterations = 10\n",
    "alpha = 0.01\n",
    "lambda1 = 0.01\n",
    "modelImplicit1 = ALS.trainImplicit(trainDf, rank, numIterations, alpha, -1, lambda1, False, 10)\n",
    "print \"modelImplicit1 has been trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second model with different hyper parameter values is trained for comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelImplicit2 has been trained\n"
     ]
    }
   ],
   "source": [
    "rank = 15\n",
    "numIterations = 20\n",
    "alpha = 0.01\n",
    "lambda1 = 0.01\n",
    "modelImplicit2 = ALS.trainImplicit(trainDf, rank, numIterations, alpha, -1, lambda1, False, 10)\n",
    "print \"modelImplicit2 has been trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:green\">Section 2.2: In a similar way to what was done higher in Section 1, we build a test dataframe which only has two columns: user and product. The rating column is added by the recommendation engine.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(user=12838, product=22941)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the (user, product) pair from the testDf and drop the rating\n",
    "testDf2 = testDf.map(lambda l: (l[0], l[1])).toDF([\"user\", \"product\"])\n",
    "testDf2.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 2.3: Getting predictions using the implicit MLlib model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get now the predictions for testDf2. Note that we need to pass in the underlying RDD to\n",
    "# predictAll. Passing in the DataFrame returns an error indicating that the method expects\n",
    "# an RDD.\n",
    "predictImplicit = modelImplicit1.predictAll(testDf2.rdd)\n",
    "\n",
    "#predictUsingDf is an RDD of \"Rating\" objects comprised of the fields: user, product, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating(user=17883, product=21000, rating=0.017978272291746304)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictImplicit.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note as well that in the case of implict ratings logic, the ratings returned by the recommendation engine are values between 0 and 1, as they correspond to a \"confidence\" level rather than explicit rating value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we will rebuild a data frame from the RDD predictUsingDf, so as to be able to use SQL.\n",
    "predictImplicitDf = predictImplicit.map(lambda r: (r.user, r.product, r.rating)).\\\n",
    "map(lambda (a,b,c): Row(a,b,c)).toDF([\"user\", \"product\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------------+\n",
      "| user|product|              rating|\n",
      "+-----+-------+--------------------+\n",
      "|17883|  21000|0.017978272291746304|\n",
      "|13700|  22900| 0.10150778559611573|\n",
      "|15201|  22900|0.018166055084698145|\n",
      "|16504|  22900|  0.0383290330738306|\n",
      "|18005|  22900| 0.03260654905695093|\n",
      "+-----+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictImplicitDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 2.4: Comparing user entries with predicted ratings and getting a Mean Squared Error</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the cell below, we will join the test table with the recommendation engine predictions into one single table / dataframe, which will allow us to calculate the accuracy of the algorithm by computing the deltas between original and computed user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+-----+-------+--------------------+\n",
      "|custId|stockCode|preference| user|product|              rating|\n",
      "+------+---------+----------+-----+-------+--------------------+\n",
      "| 12347|    21791|       3.0|12347|  21791| 0.11184186142936409|\n",
      "| 12347|    84997|       3.0|12347|  84997| 0.12314848691489971|\n",
      "| 12347|    84991|       3.0|12347|  84991|  0.1027434199056403|\n",
      "| 12347|    22376|       3.0|12347|  22376|0.023383039643338432|\n",
      "| 12347|    47559|       3.0|12347|  47559| 0.04998915932911552|\n",
      "| 12347|    22492|       3.0|12347|  22492| 0.12110006311334459|\n",
      "| 12347|    20719|       4.0|12347|  20719| 0.04370908494907677|\n",
      "| 12347|    84558|       5.0|12347|  84558|0.011325413537812721|\n",
      "| 12352|    22779|       3.0|12352|  22779| 0.01556474292436821|\n",
      "| 12359|    82613|       3.0|12359|  82613|0.011095459215197279|\n",
      "+------+---------+----------+-----+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "testDf.registerTempTable(\"testTable\")\n",
    "predictImplicitDf.registerTempTable(\"predictImplicitTable\")\n",
    "join = \"\"\"\n",
    "SELECT \n",
    "    custId, stockCode, preference, user, product, rating\n",
    "FROM \n",
    "    testTable, predictImplicitTable \n",
    "WHERE\n",
    "    custId = user and stockCode = product\"\"\"\n",
    "joinDf = sqlContext.sql(join)\n",
    "\n",
    "print joinDf.filter(\"preference >=3\").orderBy(\"custId\", \"preference\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.17997474654\n"
     ]
    }
   ],
   "source": [
    "#Calculate the Mean Squared Error for modelImplicit1.\n",
    "MSE = joinDf.map(lambda l: (l.preference - l.rating)**2).mean()\n",
    "print MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to calculate the MSE for the second model, we need to rerun the few cells above by switching one model name for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.08793275415\n"
     ]
    }
   ],
   "source": [
    "#Calculate the Mean Squared Error for modelImplicit2.\n",
    "MSE = joinDf.map(lambda l: (l.preference - l.rating)**2).mean()\n",
    "print MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the results above, it seems that modelImplict2 has a lower MSE and therefore has better accuracy. Consequently, we use model2 in the remainder of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 2.5: Manual verification of ALS recommendations for one chosen customer...</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=16248, product=22111, rating=0.0942212742424042),\n",
       " Rating(user=16248, product=23355, rating=0.08892665546439966),\n",
       " Rating(user=16248, product=22865, rating=0.07648471083984797)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The example below keeps the same customer as the one picked in Section 1 above.\n",
    "modelImplicit2.recommendProducts(16248,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stockCode=22809, description=u'SET OF 6 T-LIGHTS SANTA'),\n",
       " Row(stockCode=23157, description=u'SET OF 6 NATIVITY MAGNETS '),\n",
       " Row(stockCode=22865, description=u'HAND WARMER OWL DESIGN'),\n",
       " Row(stockCode=23419, description=u'HOME SWEET HOME BOTTLE '),\n",
       " Row(stockCode=22866, description=u'HAND WARMER SCOTTY DOG DESIGN'),\n",
       " Row(stockCode=23155, description=u'KNICKERBOCKERGLORY MAGNET ASSORTED '),\n",
       " Row(stockCode=23156, description=u'SET OF 5 MINI GROCERY MAGNETS')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reminder of what this customer bought...\n",
    "sqlContext.sql(\"\"\"SELECT distinct stockCode, description from retailPurchases \n",
    "               where custId in (16248)\"\"\").take(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stockCode=23355, description=u'HOT WATER BOTTLE KEEP CALM'),\n",
       " Row(stockCode=22865, description=u'HAND WARMER OWL DESIGN'),\n",
       " Row(stockCode=22111, description=u'SCOTTIE DOG HOT WATER BOTTLE')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is what we are recommending for them\n",
    "sqlContext.sql(\"\"\"SELECT distinct stockCode, description from retailPurchases \n",
    "               where stockCode in (22111, 23355, 22865)\"\"\").take(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The recommendations look like reasonable suggestions... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the following section, we will turn our attention to the more recent Spark ML library which is built on top of data frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <span style=\"color:blue\">Section 3 (Please ensure you've run Section 0 above)</span>\n",
    "### Use SPARK ML library and (assume) EXPLICIT user feedback on product ratings.\n",
    "### SPARK ML uses data frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 3.1: Training the explicit Spark ML models</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The syntax of Spark ML is slightly different than that of Spark MLlib. The model is trained here by \"fitting\" the algorithm to the provided input data frame, using the now familiar hyper parameters: rank and maxIter. Also note that the columns of interest (to ALS logic) in the input dataframe are selected by name using the 'userCol', 'itemCol' and 'ratingCol' keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models have been trained\n"
     ]
    }
   ],
   "source": [
    "# We train two models using different combinations for the rank and the number of iterations.\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als1 = ALS(rank=15, maxIter=15,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"preference\")\n",
    "model1 = als1.fit(trainDf)\n",
    "\n",
    "als2 = ALS(rank=2, maxIter=10,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"preference\")\n",
    "model2 = als2.fit(trainDf)\n",
    "\n",
    "print \"The models have been trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 3.2: Preparing the testing set</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As seen in previous sections, it is a best practice to clean the customers and stock test data sets from any elements which would not have been present in the training set. We covered a way to do this using SQL in previous sections. Below is a different way of getting the same result using Python/Spark transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51996\n",
      "51953\n"
     ]
    }
   ],
   "source": [
    "# A Python set is an unordered collection of unique elements. We are building below two sets of\n",
    "# customers and stock ids. The lambda function extracts the relevant column from the trainDf \n",
    "# dataframe, and we build a set which is then collected into a final array.\n",
    "customers = set(trainDf.rdd.map(lambda line: line.custId).collect())\n",
    "stock = set(trainDf.rdd.map(lambda line: line.stockCode).collect())\n",
    "\n",
    "print testDf.count()\n",
    "testDf = testDf.rdd.filter(lambda line: line.stockCode in stock and\\\n",
    "                                            line.custId in customers).toDF()\n",
    "\n",
    "print testDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two numbers printed above correspond to the values obtained higher at the end of Section 1.7, which confirms the fact that all entries where a customer Id or stock Id was not present in the training set does not get a prediction rating value..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 3.3: Getting predictions using the ML model with EXPLICIT feedback</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is an excerpt from the Spark documentation regarding the \"transform\" method used in the cell below:\n",
    "A Transformer is an abstraction that includes feature transformers and learned models. Technically, a Transformer implements a method transform(), which converts one DataFrame into another, generally by appending one or more columns. For example:\n",
    "\n",
    "- A feature transformer might take a DataFrame, read a column (e.g., text), map it into a new column (e.g., feature vectors), and output a new DataFrame with the mapped column appended.\n",
    "- A learning model might take a DataFrame, read the column containing feature vectors, predict the label for each feature vector, and output a new DataFrame with predicted labels appended as a column.\n",
    "\n",
    "<span style=\"color:red\">Note:</span> The original text from which this paragraph was copied can be found in the Spark documentation at the following link: http://spark.apache.org/docs/latest/ml-guide.html#transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(custId=17637, stockCode=20831, preference=1.0, prediction=0.5975714325904846), Row(custId=14286, stockCode=20831, preference=1.0, prediction=0.8286399245262146)]\n",
      "[Row(custId=17637, stockCode=20831, preference=1.0, prediction=0.5547059774398804), Row(custId=14286, stockCode=20831, preference=1.0, prediction=0.8869171142578125)]\n"
     ]
    }
   ],
   "source": [
    "# This transform method used below is therefore the method described in the second bullet above.\n",
    "# It will take the test set as input, and apply the model predictions to it, appending a rating\n",
    "# column and then return a new dataframe.\n",
    "predictions1 = model1.transform(testDf)\n",
    "predictions2 = model2.transform(testDf)\n",
    "\n",
    "# A a quick verification, we will print the first couple of rows from both returned dataframes.\n",
    "# We notice that the 'prediction' column was appended as expected.\n",
    "print predictions1.take(2)\n",
    "print predictions2.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Remark:</span> In this case, it can be noted that the resulting predictions dataframes already have both the original customer rating, under the column 'preference' and the model's generated rating, under the column 'prediction'. It will therefore not be needed to construct a table or dataframe which contains both, as we already have it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:green\">Section 3.4: Comparing user entries with predicted ratings and getting a Mean Squared Error</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mean Squared Error is evaluated in the same way as in previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error = 1.5996 for our first model\n",
      "Mean squared error = 1.9945 for our second model\n"
     ]
    }
   ],
   "source": [
    "meanSquaredError1 = predictions1.map(lambda line: (line.preference - line.prediction)**2).mean()\n",
    "meanSquaredError2 = predictions2.map(lambda line: (line.preference - line.prediction)**2).mean()\n",
    "    \n",
    "print 'Mean squared error = %.4f for our first model' % meanSquaredError1\n",
    "print 'Mean squared error = %.4f for our second model' % meanSquaredError2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first model seems to present better accuracy than the second, which is expected given the chosen values for rank and maxIter..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 3.5: Manual verification of ALS recommendations for one chosen customer...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now work on verifying \"manually\" the efficiency of our model. In order to do so, we will pick one customer who bought a reasonably small, yet meaningful number of items (i.e more than one or two, but not dozens) and check the top three recommendations for that particular customer in order to decide whether these make sense or not. To begin, we write a SQL query to find customers ids who bought a reasonable number of items, i.e between 5 and 10. We start with a count of 7 items (feel free to update the query below with a different count for other attemps)\n",
    "#### <span style=\"color:red\">Note:</span> We will continue using the same customer id as in previous section so as to compare outputs from different engines using the same baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(custId=17639, count=7),\n",
       " Row(custId=14641, count=7),\n",
       " Row(custId=18042, count=7),\n",
       " Row(custId=17647, count=7),\n",
       " Row(custId=18048, count=7),\n",
       " Row(custId=16248, count=7),\n",
       " Row(custId=15257, count=7),\n",
       " Row(custId=15458, count=7),\n",
       " Row(custId=15463, count=7),\n",
       " Row(custId=18064, count=7)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"select custId, count(*) as count from retailPurchases \n",
    "           group by custId having count = 7 order by count\"\"\"\n",
    "\n",
    "sqlContext.sql(query).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select customer id 16248...and check which items this customer bought..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockCode</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22809</td>\n",
       "      <td>SET OF 6 T-LIGHTS SANTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23157</td>\n",
       "      <td>SET OF 6 NATIVITY MAGNETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22865</td>\n",
       "      <td>HAND WARMER OWL DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23419</td>\n",
       "      <td>HOME SWEET HOME BOTTLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22866</td>\n",
       "      <td>HAND WARMER SCOTTY DOG DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23155</td>\n",
       "      <td>KNICKERBOCKERGLORY MAGNET ASSORTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23156</td>\n",
       "      <td>SET OF 5 MINI GROCERY MAGNETS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stockCode                          description\n",
       "0      22809              SET OF 6 T-LIGHTS SANTA\n",
       "1      23157           SET OF 6 NATIVITY MAGNETS \n",
       "2      22865               HAND WARMER OWL DESIGN\n",
       "3      23419              HOME SWEET HOME BOTTLE \n",
       "4      22866        HAND WARMER SCOTTY DOG DESIGN\n",
       "5      23155  KNICKERBOCKERGLORY MAGNET ASSORTED \n",
       "6      23156        SET OF 5 MINI GROCERY MAGNETS"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"SELECT distinct stockCode, description from retailPurchases \n",
    "               where custId in (16248)\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now obtain some recommendations for the chosen customer through our selected model.\n",
    "### Spark ML does not offer a 'recommendProducts' method as was used above with MLlib. But that is no problem, we will obtain our recommendations using the same 'transform' method which was used a few cells above with the test dataset. More specifically, we will:\n",
    "- Build a dataframe named userItems, where our selected userid is associated with every single product id in the database\n",
    "- Pass this userItems dataframe through the 'transform' method, which as seen previously, will append a 'rating' column, indicating the strength of the recommendation for our chosen user id and the current product\n",
    "- Sort the resulting 'recommendations' dataframe and select the top N rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|stockCode|custId|\n",
      "+---------+------+\n",
      "|    21231| 16248|\n",
      "|    85231| 16248|\n",
      "|    22431| 16248|\n",
      "|    23231| 16248|\n",
      "|    22631| 16248|\n",
      "+---------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build a dataframe named userItems, by selecting distinct values of all available stock codes\n",
    "# and appending our chosen customer id.\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "userItems = trainDf.select(\"stockCode\").distinct().\\\n",
    "            withColumn('custId', lit(16248))\n",
    "\n",
    "# Print a few rows from our dataframe to verify that it was built as expected.\n",
    "print userItems.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use now 'transform' to rate each item. We will also sort the returned prediction codes in descending order of prediction strength, so as to see the highest recommendations first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|stockCode|custId|prediction|\n",
      "+---------+------+----------+\n",
      "|        2| 16248| 3.4413526|\n",
      "|    90214| 16248| 3.0965843|\n",
      "|    84596| 16248| 2.5026555|\n",
      "|    84997| 16248|  2.111412|\n",
      "|    37489| 16248| 2.1043334|\n",
      "+---------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "userItems = model1.transform(userItems)\n",
    "\n",
    "#print userItems.take(5)\n",
    "print userItems.sort(\"prediction\",ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a now familiar SQL query to obtain the text description of the recommended items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stockCode                         description\n",
      "0       37489   YELLOW/PINK FLOWER DESIGN BIG MUG\n",
      "1       37489    GREEN/BLUE FLOWER DESIGN BIG MUG\n",
      "2       37489   BLUE/YELLOW FLOWER DESIGN BIG MUG\n",
      "3       37489    PINK/GREEN FLOWER DESIGN BIG MUG\n",
      "4       84596          SMALL CHOCOLATES PINK BOWL\n",
      "5       84596        SMALL MARSHMALLOWS PINK BOWL\n",
      "6       84596      BISCUITS SMALL BOWL LIGHT BLUE\n",
      "7       84596  SMALL DOLLY MIX DESIGN ORANGE BOWL\n",
      "8       84596        SMALL LICORICE DES PINK BOWL\n",
      "9       84596         MIXED NUTS LIGHT GREEN BOWL\n",
      "10      84997   BLUE 3 PIECE POLKADOT CUTLERY SET\n",
      "11      84997   PINK 3 PIECE POLKADOT CUTLERY SET\n",
      "12      84997  GREEN 3 PIECE POLKADOT CUTLERY SET\n",
      "13      84997    CHILDRENS CUTLERY RETROSPOT RED \n",
      "14      84997   RED 3 PIECE RETROSPOT CUTLERY SET\n",
      "15      84997     CHILDRENS CUTLERY POLKADOT PINK\n",
      "16      84997     CHILDRENS CUTLERY POLKADOT BLUE\n",
      "17      84997   CHILDRENS CUTLERY POLKADOT GREEN \n",
      "18      90214       \"LETTER \"\"G\"\" BLING KEY RING\"\n",
      "19      90214       \"LETTER \"\"B\"\" BLING KEY RING\"\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    distinct stockCode, description \n",
    "FROM \n",
    "    retailPurchases \n",
    "WHERE \n",
    "    stockCode in (90214, 84596, 84997, 37489)\n",
    "    ORDER BY stockCode limit 20\n",
    "\"\"\"\n",
    "items = sqlContext.sql(query)\n",
    "print items.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Section 4 (Please ensure you've run Section 0 above)</span>\n",
    "### Use SPARK ML library and (assume) IMPLICIT user feedback on product ratings.\n",
    "### SPARK ML uses data frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 4.1: Training the implicit Spark ML models</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models have been trained\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als1 = ALS(rank=15, maxIter=15, implicitPrefs=True,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"preference\")\n",
    "modelImplicit1ml = als1.fit(trainDf)\n",
    "\n",
    "als2 = ALS(rank=2, maxIter=10,implicitPrefs=True, userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"preference\")\n",
    "modelImplicit2ml = als2.fit(trainDf)\n",
    "\n",
    "print \"The models have been trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 4.2: Preparing the testing set</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As seen in previous sections, it is a best practice to clean the customers and stock test data sets from any elements which would not have been present in the training set. We covered a way to do this using SQL in previous sections. Below is a different way of getting the same result using Python/Spark transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51996\n",
      "51953\n"
     ]
    }
   ],
   "source": [
    "customers = set(trainDf.rdd.map(lambda line: line.custId).collect())\n",
    "stock = set(trainDf.rdd.map(lambda line: line.stockCode).collect())\n",
    "\n",
    "print testDf.count()\n",
    "testDf = testDf.rdd.filter(lambda line: line.stockCode in stock and\\\n",
    "                                            line.custId in customers).toDF()\n",
    "\n",
    "print testDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 4.3: Getting predictions using the ML model with IMPLICIT feedback</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is an excerpt from the Spark documentation regarding the \"transform\" method used in the cell below:\n",
    "A Transformer is an abstraction that includes feature transformers and learned models. Technically, a Transformer implements a method transform(), which converts one DataFrame into another, generally by appending one or more columns. For example:\n",
    "\n",
    "- A feature transformer might take a DataFrame, read a column (e.g., text), map it into a new column (e.g., feature vectors), and output a new DataFrame with the mapped column appended.\n",
    "- A learning model might take a DataFrame, read the column containing feature vectors, predict the label for each feature vector, and output a new DataFrame with predicted labels appended as a column.\n",
    "\n",
    "<span style=\"color:red\">Note:</span> The original text from which this paragraph was copied can be found in the Spark documentation at the following link: http://spark.apache.org/docs/latest/ml-guide.html#transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(custId=17637, stockCode=20831, preference=1.0, prediction=0.02002069726586342), Row(custId=14286, stockCode=20831, preference=1.0, prediction=0.06646830588579178)]\n",
      "[Row(custId=17637, stockCode=20831, preference=1.0, prediction=0.008741205558180809), Row(custId=14286, stockCode=20831, preference=1.0, prediction=0.03968136012554169)]\n"
     ]
    }
   ],
   "source": [
    "predictions1 = modelImplicit1ml.transform(testDf)\n",
    "predictions2 = modelImplicit2ml.transform(testDf)\n",
    "\n",
    "print predictions1.take(2)\n",
    "print predictions2.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 4.4: Comparing user entries with predicted ratings and getting a Mean Squared Error</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error = 3.7671 for our first model\n",
      "Mean squared error = 3.9502 for our second model\n"
     ]
    }
   ],
   "source": [
    "meanSquaredError1 = predictions1.map(lambda line: (line.preference - line.prediction)**2).mean()\n",
    "meanSquaredError2 = predictions2.map(lambda line: (line.preference - line.prediction)**2).mean()\n",
    "    \n",
    "print 'Mean squared error = %.4f for our first model' % meanSquaredError1\n",
    "print 'Mean squared error = %.4f for our second model' % meanSquaredError2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first model seems to present better accuracy than the second, which is expected given the chosen values for rank and maxIter..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Section 4.5: Manual verification of ALS recommendations for one chosen customer...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now work on verifying \"manually\" the efficiency of our model. In order to do so, we will pick one customer who bought a reasonably small, yet meaningful number of items (i.e more than one or two, but not dozens) and check the top three recommendations for that particular customer in order to decide whether these make sense or not. To begin, we write a SQL query to find customers ids who bought a reasonable number of items, i.e between 5 and 10. We start with a count of 7 items (feel free to update the query below with a different count for other attemps)\n",
    "#### <span style=\"color:red\">Note:</span> We will continue using the same customer id as in previous section so as to compare outputs from different engines using the same baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(custId=17639, count=7),\n",
       " Row(custId=14641, count=7),\n",
       " Row(custId=18042, count=7),\n",
       " Row(custId=17647, count=7),\n",
       " Row(custId=18048, count=7),\n",
       " Row(custId=16248, count=7),\n",
       " Row(custId=15257, count=7),\n",
       " Row(custId=15458, count=7),\n",
       " Row(custId=15463, count=7),\n",
       " Row(custId=18064, count=7)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"select custId, count(*) as count from retailPurchases \n",
    "           group by custId having count = 7 order by count\"\"\"\n",
    "\n",
    "sqlContext.sql(query).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select customer id 16248...and check which items this customer bought..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockCode</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22809</td>\n",
       "      <td>SET OF 6 T-LIGHTS SANTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23157</td>\n",
       "      <td>SET OF 6 NATIVITY MAGNETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22865</td>\n",
       "      <td>HAND WARMER OWL DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23419</td>\n",
       "      <td>HOME SWEET HOME BOTTLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22866</td>\n",
       "      <td>HAND WARMER SCOTTY DOG DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23155</td>\n",
       "      <td>KNICKERBOCKERGLORY MAGNET ASSORTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23156</td>\n",
       "      <td>SET OF 5 MINI GROCERY MAGNETS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stockCode                          description\n",
       "0      22809              SET OF 6 T-LIGHTS SANTA\n",
       "1      23157           SET OF 6 NATIVITY MAGNETS \n",
       "2      22865               HAND WARMER OWL DESIGN\n",
       "3      23419              HOME SWEET HOME BOTTLE \n",
       "4      22866        HAND WARMER SCOTTY DOG DESIGN\n",
       "5      23155  KNICKERBOCKERGLORY MAGNET ASSORTED \n",
       "6      23156        SET OF 5 MINI GROCERY MAGNETS"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"SELECT distinct stockCode, description from retailPurchases \n",
    "               where custId in (16248)\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now obtain some recommendations for the chosen customer through our selected model.\n",
    "### Spark ML does not offer a 'recommendProducts' method as was used above with MLlib. But that is no problem, we will obtain our recommendations using the same 'transform' method which was used a few cells above with the test dataset. More specifically, we will:\n",
    "- Build a dataframe named userItems, where our selected userid is associated with every single product id in the database\n",
    "- Pass this userItems dataframe through the 'transform' method, which as seen previously, will append a 'rating' column, indicating the strength of the recommendation for our chosen user id and the current product\n",
    "- Sort the resulting 'recommendations' dataframe and select the top N rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|stockCode|custId|\n",
      "+---------+------+\n",
      "|    21231| 16248|\n",
      "|    85231| 16248|\n",
      "|    22431| 16248|\n",
      "|    23231| 16248|\n",
      "|    22631| 16248|\n",
      "+---------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations for one particular user\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "userItems = trainDf.select(\"stockCode\").distinct().\\\n",
    "            withColumn('custId', lit(16248))\n",
    "\n",
    "print userItems.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use now 'transform' to rate each item. We will also sort the returned prediction codes in descending order of prediction strength, so as to see the highest recommendations first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----------+\n",
      "|stockCode|custId| prediction|\n",
      "+---------+------+-----------+\n",
      "|    22111| 16248|0.114170134|\n",
      "|    23355| 16248| 0.10992701|\n",
      "|    22866| 16248| 0.10629847|\n",
      "|    22865| 16248| 0.10552523|\n",
      "|    84029| 16248|0.103145994|\n",
      "+---------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userItems = modelImplicit1ml.transform(userItems)\n",
    "\n",
    "#print userItems.take(5)\n",
    "userItems.sort(\"prediction\",ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a now familiar SQL query to obtain the text description of the recommended items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   stockCode                          description\n",
      "0      22111         SCOTTIE DOG HOT WATER BOTTLE\n",
      "1      22865               HAND WARMER OWL DESIGN\n",
      "2      22866        HAND WARMER SCOTTY DOG DESIGN\n",
      "3      23355           HOT WATER BOTTLE KEEP CALM\n",
      "4      84029       RED WOOLLY HOTTIE WHITE HEART.\n",
      "5      84029  KNITTED UNION FLAG HOT WATER BOTTLE\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    distinct stockCode, description \n",
    "FROM \n",
    "    retailPurchases \n",
    "WHERE \n",
    "    stockCode in (22111, 23355, 22866, 22865, 84029)\n",
    "    ORDER BY stockCode\n",
    "\"\"\"\n",
    "items = sqlContext.sql(query)\n",
    "print items.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:green\">Section 4.6: Taking a look at the ALS internals...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ALS model exposes the matrices resulting from the factorization as userFactors and ItemFactors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the first few rows from the usersFactor matrix obtained from the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=12350, features=[-0.013113889843225479, 0.05081048607826233]),\n",
       " Row(id=12360, features=[-0.2741982042789459, 0.4235096573829651]),\n",
       " Row(id=12370, features=[0.11715137958526611, 0.23450566828250885]),\n",
       " Row(id=12380, features=[-0.03724483400583267, 0.29389825463294983]),\n",
       " Row(id=12390, features=[-0.15921206772327423, 0.16143059730529785])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelImplicit2ml.userFactors.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking out the representation of the matrix, it is a DataFrame with an integer representing the Item and an array of double values representing the internal encoding of the item according to the chosen rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, features: array<float>]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelImplicit2ml.itemFactors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second model was generated with a rank value of 2, so the features array has two entries as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=10080, features=[0.007301546633243561, 0.04111911728978157]),\n",
       " Row(id=10120, features=[-0.033222559839487076, 0.13802224397659302]),\n",
       " Row(id=15030, features=[0.00714927027001977, 0.020543742924928665]),\n",
       " Row(id=15060, features=[0.0944393128156662, 0.2238655388355255]),\n",
       " Row(id=16010, features=[-0.0018164529465138912, 0.02436750754714012])]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelImplicit2ml.itemFactors.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few cells higher, we ran predictions for customer id using modelImplicit1ml<span style=\"color:red\">16248</span> and obtained a rating of <span style=\"color:red\">0.114170134</span> for product <span style=\"color:red\">22111</span>. Let's reconstruct this result by manipulating directly the feature matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will first extract the Vector representing user id 16248 from the userFactors matrix and print it. The vector has 15 components, since modelImplicit1 was built with a rank of 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02880237 -0.03255107 -0.00068029  0.03202556 -0.04235569  0.00507769\n",
      " -0.01419941  0.02616715  0.01925078 -0.04078222 -0.06489316  0.0342073\n",
      "  0.03402569  0.00997772  0.00766637]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors, DenseMatrix\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from numpy import array\n",
    "v1=Vectors.dense(modelImplicit1ml.userFactors.rdd.lookup(16248))\n",
    "print v1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, we will extract the Vector representing product 22111 from the itemFactors matrix. This vector has 15 components as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01636196 -0.60772979  0.15177801  0.33173507 -0.27724168  0.39341718\n",
      " -0.02558193  0.10382893  0.00441691 -0.40955025 -0.53257501  0.16183987\n",
      "  0.24687007 -0.13434839  0.34330273]\n"
     ]
    }
   ],
   "source": [
    "v2=DenseVector(modelImplicit1ml.itemFactors.rdd.lookup(22111))\n",
    "print v2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the dot product of both vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11417013119362149"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1[0].dot(v2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Citation\n",
    "Daqing Chen, Sai Liang Sain, and Kun Guo, Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining, Journal of Database Marketing and Customer Strategy Management, Vol. 19, No. 3, pp. 197Ã¢â‚¬â€œ208, 2012 (Published online before print: 27 August 2012. doi: 10.1057/dbm.2012.17)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}